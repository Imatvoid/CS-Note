# 设计一个百万级用户抽奖系统

缓存

限流

降级

## 系统特点和本质

抽奖、抢红包、秒杀，这类系统其实都有一些共同的特点，那就是在某个时间点会瞬间涌入大量的人来点击系统，给系统造成瞬间高于平时百倍、千倍甚至几十万倍的流量压力。

瞬时超高并发的流量，应该如何设计流量削峰的架构来应对，才能保证系统不会突然跨掉？



## 限流

### 过滤重复请求

web前端,限制点击次数

服务器站点
a）同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面
b）同一个item的查询，例如手机车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面
如此限流，又有99%的流量会被拦截在站点层

后端服务
微服务本身的负载均衡
服务内部限流算法,漏斗



### tips  结束后暴力拦截流量

其实秒杀、抢红包、抽奖，这类系统有一个共同的特点，那就是假设有50万请求涌入进来，可能前5万请求就直接把事儿干完了，甚至是前500请求就把事儿干完了，后续的几十万流量是无效的，不需要让他们进入后台系统执行业务逻辑了。

举个例子，秒杀商品，假设有50万人抢一个特价手机，人家就准备了100台手机，那么50万请求瞬间涌入，其实前500个请求就把手机抢完了，后续的几十万请求没必要让他转发到Tomcat服务中去执行秒杀业务逻辑了，不是吗？

抽奖、红包都是一样的 ，可能50万请求涌入，但是前1万个请求就把奖品都抽完了，或者把红包都抢完了，后续的流量其实已经不需要放到抽奖服务上去了，直接暴力拦截返回抽奖结束就可以了。

这样的话，其实在负载均衡这一层（可以考虑用Nginx之类的来实现）就可以拦截掉99%的无效流量。

所以必须让抽奖服务跟负载均衡之间有一个状态共享的机制。就是说抽奖服务一旦全部开奖完毕，直接更新一个共享状态。然后负载均衡感知到了之后，后续请求全部拦截掉返回一个抽奖结束的标识就可以了。这么做可能就会做到50万人一起请求，结果就可能2万请求到了后台的Tomcat抽奖服务中，48万请求直接拦截掉了。

我们可以基于Redis来实现这种共享抽奖状态，它非常轻量级，很适合两个层次的系统的共享访问。当然其实用ZooKeeper也是可以的，在负载均衡层可以基于zk客户端监听某个znode节点状态。一旦抽奖结束，抽奖服务更新zk状态，负载均衡层会感知到。

## 降级

对于超过系统水位线的请求，直接采取 「Fail-Fast」原则，拒绝掉。

后端服务


## 系统优化

### 后续耗时服务mq解耦转异步

- 秒杀     --  后续流程如发货

- 抽奖     --  后续流程如发货

  

- 抢红包  --  后续实际资金转账

##  总结

其实对于商品秒杀、抽奖活动、抢红包类的系统而言，架构设计的思路很多都是类似的，核心思路都是对于这种瞬时超高流量的系统，**尽可能在负载均衡层就把99%的无效流量拦截掉,尽量把流量拦截在上游**
然后在1%的流量进入核心业务服务后，此时每秒并发还是可能会上万，那么可以基于Redis实现核心业务逻辑 ，抗住上万并发。
最后对于类似秒杀商品发货、抽奖商品发货、红包资金转账之类的非常耗时的操作，完全可以基于MQ来限流削峰，后台有一个服务慢慢执行即可。



## 参考

https://coding.imooc.com/class/chapter/168.html#Anchor

https://www.cnblogs.com/doit8791/p/9380899.html
https://juejin.im/entry/59c34acef265da066d33456c
https://juejin.im/post/5bb05d786fb9a05d1d2e1e68
https://www.ibm.com/developerworks/cn/web/wa-design-small-and-good-kill-system/index.html
https://yq.aliyun.com/articles/69704?utm_campaign=wenzhang&utm_medium=article&utm_source=QQ-qun&utm_content=m_10737